import h5py
import numpy as np
import tensorflow as tf
import math

class RadioMLSequence(tf.keras.utils.Sequence):
    def __init__(self, hdf5_path, batch_size, indices, num_nodes=32, sigma=1.0, mode='binary'):
        self.hdf5_path = hdf5_path
        self.batch_size = batch_size
        self.indices = indices
        self.num_nodes = num_nodes
        self.sigma = sigma
        self.mode = mode
        self.num_classes = 2 if mode == 'binary' else 24
        
        # åˆå§‹åŒ–ç´¢å¼•æ˜ å°„
        self.local_indices = np.arange(len(self.indices))
        np.random.shuffle(self.local_indices)
        self.total_len = len(self.indices)

        # --- è®¡ç®—ç‰©ç†åº•å™ª (åªè¯»å°‘é‡æ•°æ®) ---
        print("æ­£åœ¨è®¡ç®—æ•°æ®é›†åº•å™ªåŸºå‡† (ä»…è¯»å–å°‘é‡æ ·æœ¬)...")
        with h5py.File(self.hdf5_path, 'r') as f:
            self.feature_dim = f['X'].shape[1] * f['X'].shape[2] // self.num_nodes
            
            # åªè¯»å–å‰ 2000 ä¸ªæ ·æœ¬æ¥ä¼°ç®—åº•å™ªï¼Œè€Œä¸æ˜¯è¯»å–å…¨éƒ¨
            sample_size = min(2000, len(self.indices))
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å…ˆæŠŠ indices æ’åºæ‰èƒ½ç”¨äº h5py è¯»å–
            sample_indices = np.sort(self.indices[:sample_size])
            
            temp_Z = f['Z'][sample_indices]
            temp_X = f['X'][sample_indices]
            
            # æ‰¾åˆ°æœ€å° SNR
            min_snr = np.min(temp_Z)
            noise_idx = np.where(temp_Z == min_snr)[0]
            
            if len(noise_idx) > 0:
                self.noise_std = np.std(temp_X[noise_idx])
            else:
                powers = np.mean(np.var(temp_X, axis=1), axis=1)
                self.noise_std = np.sqrt(np.min(powers))
                
            print(f"âœ… åº•å™ªè®¡ç®—å®Œæ¯•: Std={self.noise_std:.6f} (åŸºäº {min_snr}dB æ ·æœ¬)")
            print(f"ğŸš€ æ•°æ®ç”Ÿæˆå™¨å°±ç»ª! (æ‡’åŠ è½½æ¨¡å¼: è®­ç»ƒæ—¶å®æ—¶è¯»å–ç¡¬ç›˜)")

    def __len__(self):
        return math.ceil(self.total_len / self.batch_size)

    def __getitem__(self, idx):
        # 1. ç¡®å®šå½“å‰ batch çš„é€»è¾‘ç´¢å¼•
        start = idx * self.batch_size
        end = min((idx + 1) * self.batch_size, self.total_len)
        current_batch_size = end - start
        
        # è·å–å½“å‰ batch åœ¨åŸå§‹æ•°æ®é›†ä¸­çš„çœŸå®ç´¢å¼•
        # self.local_indices æ˜¯æ‰“ä¹±çš„ 0~Nï¼Œself.indices æ˜¯ä¼ å…¥çš„æœ‰æ•ˆæ ·æœ¬ ID
        batch_local_idx = self.local_indices[start:end]
        real_indices = self.indices[batch_local_idx]
        
        # h5py è¦æ±‚ç´¢å¼•å¿…é¡»æ˜¯æ’åºçš„ (Increasing order)
        # æˆ‘ä»¬å…ˆæ’åºè¯»å–ï¼Œç„¶åå†æ‰“ä¹±å›æ¥ (æˆ–è€…ç›´æ¥ä½¿ç”¨æ’åºåçš„æ•°æ®ï¼Œå¯¹è®­ç»ƒå½±å“ä¸å¤§)
        sorted_real_indices = np.sort(real_indices)

        # 2. å®æ—¶ä»ç¡¬ç›˜è¯»å–æ•°æ® (æ ¸å¿ƒä¿®æ”¹)
        with h5py.File(self.hdf5_path, 'r') as f:
            X_batch = f['X'][sorted_real_indices]
            Z_batch = f['Z'][sorted_real_indices]
            
            if self.mode != 'binary':
                Y_batch = f['Y'][sorted_real_indices]
            else:
                # äºŒåˆ†ç±»æ¨¡å¼ä¸‹ï¼Œå…ˆç»™æ‰€æœ‰æ ·æœ¬æ‰“ä¸Š "H1" (æœ‰ä¿¡å·) æ ‡ç­¾
                # åé¢æˆ‘ä»¬ä¼šæŠŠä¸€åŠçš„æ•°æ®è¦†ç›–ä¸º "H0" (çº¯å™ªå£°)
                # å½¢çŠ¶: [batch, 2] -> [H0_prob, H1_prob]
                # åˆå§‹åŒ–ä¸º [0, 1] å³å…¨éƒ¨æ˜¯ H1
                Y_new = np.zeros((current_batch_size, 2), dtype=np.float32)
                Y_new[:, 1] = 1.0 
                Y_batch = Y_new

        # 3. æ•°æ®å¢å¼º/å™ªå£°æ³¨å…¥ (å†…å­˜ä¸­å¤„ç†)
        if self.mode == 'binary':
            noise_count = current_batch_size // 2
            if noise_count > 0:
                # ç”Ÿæˆçº¯å™ªå£°æ•°æ® (H0)
                noise_data = np.random.normal(0, self.noise_std, size=(noise_count, 1024, 2))
                
                # è¦†ç›–ååŠéƒ¨åˆ†æ•°æ®
                X_batch[-noise_count:] = noise_data
                Y_batch[-noise_count:, 0] = 1.0 # H0 = 1
                Y_batch[-noise_count:, 1] = 0.0 # H1 = 0
                Z_batch[-noise_count:] = -100   # æ ‡è®°ä¿¡å™ªæ¯”æä½

        # 4. è½¬æ¢æ•°æ®å½¢çŠ¶ä»¥é€‚é… GCN
        X_reshaped = X_batch.reshape(-1, self.num_nodes, self.feature_dim)
        X_tensor = tf.convert_to_tensor(X_reshaped, dtype=tf.float32)
        
        # 5. åŠ¨æ€è®¡ç®—é‚»æ¥çŸ©é˜µ A
        # (Batch, Nodes, 1, Feats) - (Batch, 1, Nodes, Feats)
        diff = tf.expand_dims(X_tensor, 2) - tf.expand_dims(X_tensor, 1)
        dist_sq = tf.reduce_sum(tf.square(diff), axis=-1)
        A_batch = tf.exp(-dist_sq / (self.sigma ** 2))
        
        # å½’ä¸€åŒ– A
        D = tf.reduce_sum(A_batch, axis=-1, keepdims=True)
        A_batch_norm = A_batch / (D + 1e-6)

        return [X_tensor, A_batch_norm], Y_batch

    def on_epoch_end(self):
        # æ¯ä¸ª epoch ç»“æŸåé‡æ–°æ‰“ä¹±ç´¢å¼•ï¼Œä¿è¯éšæœºæ€§
        np.random.shuffle(self.local_indices)

def get_generators(hdf5_path, batch_size=32, num_nodes=32, split_ratio=0.8, max_samples=None):
    # è¿™ä¸€æ­¥åªè¯»å–æ–‡ä»¶å…ƒæ•°æ®ï¼Œéå¸¸å¿«
    with h5py.File(hdf5_path, 'r') as f:
        total_samples = f['X'].shape[0]
        # è·å–ç‰¹å¾ç»´åº¦ç”¨äºåç»­å ä½ï¼Œä¸è¯»å–å®é™…æ•°æ®
        feature_dim = f['X'].shape[1] * f['X'].shape[2] // num_nodes
        
    if max_samples: total_samples = min(total_samples, max_samples)
    
    all_indices = np.arange(total_samples)
    np.random.shuffle(all_indices)
    
    split_idx = int(total_samples * split_ratio)
    train_indices = all_indices[:split_idx]
    val_indices = all_indices[split_idx:]
    
    # å®ä¾‹åŒ–ç”Ÿæˆå™¨ (ç°åœ¨æ˜¯è½»é‡çº§çš„)
    train_gen = RadioMLSequence(hdf5_path, batch_size, train_indices, num_nodes, mode='binary')
    val_gen = RadioMLSequence(hdf5_path, batch_size, val_indices, num_nodes, mode='binary')
    
    return train_gen, val_gen, 2, feature_dim